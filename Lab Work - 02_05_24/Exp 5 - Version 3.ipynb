{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "     support     itemsets\n",
      "0  0.036344  (Alfajores)\n",
      "1  0.016059   (Baguette)\n",
      "2  0.327205      (Bread)\n",
      "3  0.040042    (Brownie)\n",
      "4  0.103856       (Cake)\n",
      "\n",
      "Association Rules:\n",
      "    antecedents  consequents  antecedent support  consequent support   support  \\\n",
      "0  (Alfajores)     (Coffee)            0.036344            0.478394  0.019651   \n",
      "1     (Coffee)  (Alfajores)            0.478394            0.036344  0.019651   \n",
      "2     (Pastry)      (Bread)            0.086107            0.327205  0.029160   \n",
      "3      (Bread)     (Pastry)            0.327205            0.086107  0.029160   \n",
      "4    (Brownie)     (Coffee)            0.040042            0.478394  0.019651   \n",
      "\n",
      "   confidence      lift  representativity  leverage  conviction  \\\n",
      "0    0.540698  1.130235               1.0  0.002264    1.135648   \n",
      "1    0.041078  1.130235               1.0  0.002264    1.004936   \n",
      "2    0.338650  1.034977               1.0  0.000985    1.017305   \n",
      "3    0.089119  1.034977               1.0  0.000985    1.003306   \n",
      "4    0.490765  1.025860               1.0  0.000495    1.024293   \n",
      "\n",
      "   zhangs_metric   jaccard  certainty  kulczynski  \n",
      "0       0.119574  0.039693   0.119446    0.290888  \n",
      "1       0.220910  0.039693   0.004912    0.290888  \n",
      "2       0.036980  0.075908   0.017011    0.213884  \n",
      "3       0.050231  0.075908   0.003296    0.213884  \n",
      "4       0.026259  0.039398   0.023717    0.265921  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Bakery.csv\"  # Update with your file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Grouping items by transactions\n",
    "transactions = df.groupby(\"TransactionNo\")[\"Items\"].apply(list).tolist()\n",
    "\n",
    "# Convert transactions to one-hot encoded DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori algorithm to find frequent itemsets\n",
    "min_support = 0.01  # Set minimum support threshold\n",
    "frequent_itemsets = apriori(df_encoded, min_support=min_support, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.0)\n",
    "\n",
    "# Display results\n",
    "print(\"Frequent Itemsets:\\n\", frequent_itemsets.head())\n",
    "print(\"\\nAssociation Rules:\\n\", rules.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jain\\AppData\\Local\\Temp\\ipykernel_16116\\526924277.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  transactions = df.dropna().applymap(str).values.tolist()\n",
      "C:\\Users\\Jain\\AppData\\Local\\Temp\\ipykernel_16116\\526924277.py:15: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  basket_encoded = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequent Itemsets (Iteration 1 - 1-itemsets):\n",
      "      itemsets   support\n",
      "4    (Weekday)  0.624518\n",
      "0  (Afternoon)  0.564149\n",
      "3    (Morning)  0.409811\n",
      "5    (Weekend)  0.375482\n",
      "2     (Coffee)  0.266787\n",
      "1      (Bread)  0.162140\n",
      "\n",
      "Frequent Itemsets (Iteration 2 - 2-itemsets):\n",
      "                itemsets   support\n",
      "7   (Afternoon, Weekday)  0.354659\n",
      "12    (Weekday, Morning)  0.252304\n",
      "8   (Weekend, Afternoon)  0.209489\n",
      "11     (Weekday, Coffee)  0.172770\n",
      "13    (Weekend, Morning)  0.157507\n",
      "6    (Afternoon, Coffee)  0.137660\n",
      "10     (Coffee, Morning)  0.124884\n",
      "9       (Bread, Weekday)  0.102014\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"Bakery.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert data into a list of transactions, ensuring all items are strings\n",
    "transactions = df.dropna().applymap(str).values.tolist()\n",
    "\n",
    "# Apply TransactionEncoder to create one-hot encoded DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions, sparse=True)\n",
    "basket_encoded = pd.DataFrame.sparse.from_spmatrix(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori algorithm with a minimum support threshold of 30%\n",
    "frequent_itemsets = apriori(basket_encoded, min_support=0.1, use_colnames=True)\n",
    "\n",
    "# Sort frequent itemsets by support (descending)\n",
    "frequent_itemsets = frequent_itemsets.sort_values(by='support', ascending=False)\n",
    "\n",
    "# Group itemsets by their length to identify each iteration\n",
    "for k in range(1, frequent_itemsets['itemsets'].apply(len).max() + 1):\n",
    "    print(f\"\\nFrequent Itemsets (Iteration {k} - {k}-itemsets):\")\n",
    "    iteration_itemsets = frequent_itemsets[frequent_itemsets['itemsets'].apply(lambda x: len(x) == k)]\n",
    "    print(iteration_itemsets[['itemsets', 'support']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
